{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf1be83-f297-4de8-ad19-d88a6e2e47b5",
   "metadata": {},
   "source": [
    "# Анализ датасетов, сгенерированных моделью DeepSeek Chat, с помощью стандартных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97477742-ba32-469e-aae3-c897d2e9e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_PREFIX = 'deepseek_essays'\n",
    "DF_SPLIT = 9000\n",
    "DF_COUNT = 5\n",
    "THRESHOLD=0.99\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1ecb18da-1111-4dac-a03e-cf0517b9ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "68bab0ae-85f5-4236-a9c7-1cce30ba6d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x31292fb10>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eaba4137-e4e6-4d65-ab1b-1c3b7114bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/human_essays.csv\", encoding=\"utf-8\").assign(label=0)[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1bfc91a3-13e2-40da-b5fb-72a13eddfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(orig_df: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает датасет из CSV, добавляет метку и объединяет с исходным DataFrame. Затем перемешивает строки.\n",
    "\n",
    "    :param orig_df: исходный DataFrame\n",
    "    :param filename: путь к CSV-файлу\n",
    "    :return: объединённый и перемешанный DataFrame\n",
    "    \"\"\"\n",
    "    new_data = pd.read_csv(filename, encoding=\"utf-8\").assign(label=1)[[\"text\", \"label\"]]\n",
    "\n",
    "    result = pd.concat([orig_df, new_data], ignore_index=True).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "515c723c-41a3-467f-bb27-e341c6b0ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    get_dataset(df[0:DF_SPLIT], f\"../datasets/{FILE_NAME_PREFIX}_{i}.csv\")\n",
    "    for i in range(1, DF_COUNT + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "017fc3e6-ee38-48b2-ba77-42e592dce0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12000, 2), (12000, 2), (11999, 2), (12000, 2), (12000, 2)]\n"
     ]
    }
   ],
   "source": [
    "sizes = [dataset.shape for dataset in datasets]\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "38f9f073-8681-415d-8dbe-6b2e5ac86432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table of Contents\\n 1. Faith Provides Life’s M...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Organizational change is often associated with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. EMR I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The dramatic festivals of ancient Athens were ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gnomial Functions Inc. wants to determine the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The concept of divine judgement stands as a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Table of Contents\\n 1. The Event, Key Dates, a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. Forma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Patients with diabetes mellitus almost always ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Of all types of entertainment, sports games su...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Having received impressive acclaim and providi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>For a healthcare organization, maintaining con...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The suggested strategies to mitigate the effec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>It isn’t easy to single out the central direct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Decision-making is an essential factor within ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Introduction\\n\\nThe incident which led to this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The offered case study revolves around the cha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Table of Contents\\n 1. Response to Scenario 1\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The world we live in today has continuously ev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Today, the level of integration between physic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0   Table of Contents\\n 1. Faith Provides Life’s M...      0\n",
       "1   Organizational change is often associated with...      0\n",
       "2   Table of Contents\\n 1. Introduction\\n 2. EMR I...      0\n",
       "3   The dramatic festivals of ancient Athens were ...      1\n",
       "4   Gnomial Functions Inc. wants to determine the ...      0\n",
       "5   The concept of divine judgement stands as a co...      1\n",
       "6   Table of Contents\\n 1. The Event, Key Dates, a...      0\n",
       "7   Table of Contents\\n 1. Introduction\\n 2. Forma...      0\n",
       "8   Patients with diabetes mellitus almost always ...      0\n",
       "9   Of all types of entertainment, sports games su...      0\n",
       "10  Having received impressive acclaim and providi...      0\n",
       "11  For a healthcare organization, maintaining con...      0\n",
       "12  The suggested strategies to mitigate the effec...      0\n",
       "13  It isn’t easy to single out the central direct...      0\n",
       "14  Decision-making is an essential factor within ...      0\n",
       "15  Introduction\\n\\nThe incident which led to this...      0\n",
       "16  The offered case study revolves around the cha...      0\n",
       "17  Table of Contents\\n 1. Response to Scenario 1\\...      0\n",
       "18  The world we live in today has continuously ev...      0\n",
       "19  Today, the level of integration between physic...      0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea6a1c-e831-49c7-a085-648a0b88fc09",
   "metadata": {},
   "source": [
    "### Метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6716bdab-3f39-4c60-8ea4-639bea9fe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_precision(y_true, y_scores, min_precision=0.995):\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        y_true, y_scores\n",
    "    )\n",
    "\n",
    "    valid = precision[:-1] >= min_precision\n",
    "\n",
    "    if not np.any(valid):\n",
    "        return {\n",
    "            \"recall\": 0.0,\n",
    "            \"precision\": float(precision.max()),\n",
    "            \"threshold\": None,\n",
    "            \"threshold_found\": False\n",
    "        }\n",
    "\n",
    "    idx = np.argmax(recall[:-1][valid])\n",
    "    valid_indices = np.where(valid)[0]\n",
    "    best_idx = valid_indices[idx]\n",
    "\n",
    "    return {\n",
    "        \"recall\": float(recall[best_idx]),\n",
    "        \"precision\": float(precision[best_idx]),\n",
    "        \"threshold\": float(thresholds[best_idx]),\n",
    "        \"threshold_found\": True\n",
    "    }\n",
    "\n",
    "def fp_metrics(y_true, y_scores, threshold):\n",
    "    y_pred = (y_scores >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return {\n",
    "        \"fp\": int(fp),\n",
    "        \"fpr\": fp / (fp + tn + 1e-9),\n",
    "        \"precision\": tp / (tp + fp + 1e-9),\n",
    "        \"recall\": tp / (tp + fn + 1e-9),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb7fe3-d650-4fd4-bd91-da5c2ae20d78",
   "metadata": {},
   "source": [
    "### LogisticRegression + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c6777932-1d18-4c92-9a2a-073d8ad2cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_features(model, vectorizer, top_n=20):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    coefs = model.coef_[0]\n",
    "    \n",
    "    top_positive_idx = coefs.argsort()[::-1][:top_n]\n",
    "    top_negative_idx = coefs.argsort()[:top_n]\n",
    "\n",
    "    print(\"TOP words =======================\")\n",
    "    print(\"Top positive words:\")\n",
    "    for i in top_positive_idx:\n",
    "        print(f\"{feature_names[i]}: {coefs[i]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop negative words:\")\n",
    "    for i in top_negative_idx:\n",
    "        print(f\"{feature_names[i]}: {coefs[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c1f9bc29-7204-4a95-a998-59fabc9da4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_classification_report(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[\"text\"],\n",
    "        data[\"label\"],\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=data[\"label\"],\n",
    "    )\n",
    "\n",
    "    from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS  \n",
    "    custom_stop_words = [\"web\", \"2018\", \"2019\", \"2020\", \"2017\", \"2021\", \"2016\", \"al\", \"et\", \"et al\"]\n",
    "    all_stop_words = list(ENGLISH_STOP_WORDS.union(custom_stop_words))\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "        stop_words=all_stop_words\n",
    "    )\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_scores = model.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "    rap = recall_at_precision(\n",
    "        y_test,\n",
    "        y_scores,\n",
    "        min_precision=THRESHOLD\n",
    "    )\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (y_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(y_test, y_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(y_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    show_top_features(model, vectorizer, top_n=15)\n",
    "\n",
    "    return classification_report(y_test, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2aa76a78-0a67-49f2-9991-f6229cad567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP words =======================\n",
      "Top positive words:\n",
      "ultimately: 5.6045\n",
      "profound: 5.3635\n",
      "merely: 4.5388\n",
      "like: 4.2667\n",
      "complex: 3.3850\n",
      "critical: 3.1356\n",
      "furthermore: 2.9599\n",
      "narrative: 2.9329\n",
      "fundamental: 2.8823\n",
      "foundational: 2.8596\n",
      "fundamentally: 2.8095\n",
      "core: 2.7160\n",
      "powerful: 2.5399\n",
      "strategic: 2.3604\n",
      "underscores: 2.3498\n",
      "\n",
      "Top negative words:\n",
      "people: -5.3776\n",
      "references: -2.8956\n",
      "used: -2.4735\n",
      "according: -2.3847\n",
      "various: -2.3820\n",
      "journal: -2.2876\n",
      "main: -2.2474\n",
      "help: -2.2078\n",
      "different: -2.1963\n",
      "information: -2.0806\n",
      "important: -2.0545\n",
      "reference: -2.0538\n",
      "example: -2.0133\n",
      "author: -1.8983\n",
      "addition: -1.8967\n",
      "TOP words =======================\n",
      "Top positive words:\n",
      "background context: 5.3877\n",
      "context: 5.0184\n",
      "background: 4.3548\n",
      "like: 4.1996\n",
      "profound: 3.7389\n",
      "complex: 3.4040\n",
      "critical: 3.1563\n",
      "narrative: 3.0616\n",
      "merely: 3.0478\n",
      "core: 2.9605\n",
      "conclusion: 2.9340\n",
      "foundational: 2.8748\n",
      "strategic: 2.8354\n",
      "systemic: 2.5937\n",
      "particularly: 2.5429\n",
      "\n",
      "Top negative words:\n",
      "people: -5.6318\n",
      "references: -2.6742\n",
      "journal: -2.4998\n",
      "according: -2.3123\n",
      "used: -2.2862\n",
      "main: -2.1606\n",
      "various: -2.0957\n",
      "help: -2.0924\n",
      "information: -2.0409\n",
      "different: -2.0278\n",
      "important: -2.0190\n",
      "patients: -1.9687\n",
      "person: -1.9606\n",
      "company: -1.8779\n",
      "addition: -1.8416\n",
      "TOP words =======================\n",
      "Top positive words:\n",
      "ultimately: 5.0661\n",
      "profound: 5.0659\n",
      "like: 4.7029\n",
      "merely: 4.2830\n",
      "complex: 3.7098\n",
      "critical: 3.2889\n",
      "furthermore: 3.2652\n",
      "foundational: 3.2167\n",
      "fundamentally: 2.9094\n",
      "powerful: 2.8986\n",
      "narrative: 2.8786\n",
      "core: 2.8443\n",
      "fundamental: 2.6750\n",
      "systemic: 2.6166\n",
      "particularly: 2.5738\n",
      "\n",
      "Top negative words:\n",
      "people: -5.6899\n",
      "used: -2.6069\n",
      "according: -2.5712\n",
      "various: -2.4260\n",
      "main: -2.3731\n",
      "important: -2.2607\n",
      "help: -2.2559\n",
      "different: -2.2389\n",
      "example: -2.1676\n",
      "information: -2.1290\n",
      "addition: -2.0888\n",
      "references: -2.0647\n",
      "person: -2.0346\n",
      "reference: -1.9704\n",
      "author: -1.9645\n",
      "TOP words =======================\n",
      "Top positive words:\n",
      "profound: 4.3646\n",
      "merely: 3.6898\n",
      "ultimately: 3.6179\n",
      "critical: 3.3858\n",
      "foundational: 3.3629\n",
      "complex: 3.2551\n",
      "core: 3.1250\n",
      "like: 3.0921\n",
      "narrative: 3.0104\n",
      "framework: 2.8589\n",
      "https: 2.7333\n",
      "systemic: 2.7228\n",
      "strategic: 2.7156\n",
      "primary: 2.6490\n",
      "particularly: 2.5700\n",
      "\n",
      "Top negative words:\n",
      "people: -6.1045\n",
      "used: -3.0795\n",
      "according: -2.5844\n",
      "different: -2.5223\n",
      "various: -2.5078\n",
      "help: -2.5017\n",
      "important: -2.4648\n",
      "main: -2.4543\n",
      "patients: -2.4445\n",
      "information: -2.3791\n",
      "example: -2.1007\n",
      "author: -2.0762\n",
      "way: -2.0165\n",
      "possible: -2.0050\n",
      "person: -1.9885\n",
      "TOP words =======================\n",
      "Top positive words:\n",
      "profound: 3.8275\n",
      "essay: 3.2398\n",
      "foundational: 3.1707\n",
      "synthesis: 3.1010\n",
      "systemic: 3.0592\n",
      "critical: 3.0283\n",
      "alternative: 2.9180\n",
      "essay argues: 2.8715\n",
      "like: 2.8296\n",
      "strategic: 2.7600\n",
      "narrative: 2.7281\n",
      "core: 2.7089\n",
      "furthermore: 2.7033\n",
      "argues: 2.6885\n",
      "counterarguments: 2.6735\n",
      "\n",
      "Top negative words:\n",
      "people: -4.1982\n",
      "used: -2.0185\n",
      "references: -1.9410\n",
      "company: -1.7780\n",
      "journal: -1.7769\n",
      "different: -1.7274\n",
      "information: -1.6930\n",
      "various: -1.6699\n",
      "according: -1.6693\n",
      "help: -1.5832\n",
      "patients: -1.4589\n",
      "person: -1.4579\n",
      "example: -1.4525\n",
      "reference: -1.3924\n",
      "society: -1.3855\n"
     ]
    }
   ],
   "source": [
    "log_results = []\n",
    "for df in datasets:\n",
    "    log_results.append(get_log_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ee3ed0a3-36fe-46f2-9c4f-b09830fd97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      0.99       600\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       0.99      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      0.99      0.99       600\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       0.99      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       600\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1            1.0000             True   6 0.0033     0.9901  1.0000\n",
      "       2            1.0000             True   6 0.0033     0.9901  1.0000\n",
      "       3            0.9983             True   6 0.0033     0.9901  0.9983\n",
      "       4            0.9950             True   6 0.0033     0.9900  0.9950\n",
      "       5            1.0000             True   6 0.0033     0.9901  1.0000\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(log_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dcaf1-758c-41b1-9b89-7de022655f3e",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1efefea0-0cb6-44c3-8325-ec5f0213ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boost_classification_report(data):\n",
    "    df = data.copy()\n",
    "    df[\"tokens\"] = df[\"text\"].apply(lambda text: simple_preprocess(str(text)))\n",
    "\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=df[\"tokens\"],\n",
    "        vector_size=300,\n",
    "        window=7,\n",
    "        min_count=2,\n",
    "        workers=12,\n",
    "        sg=1,\n",
    "    )\n",
    "\n",
    "    def text_to_vector(tokens, model):\n",
    "        vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "    X = np.vstack([text_to_vector(tokens, w2v_model) for tokens in df[\"tokens\"]])\n",
    "    y = df[\"label\"].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.5,\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=12,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    rap = recall_at_precision(y_test, y_scores, min_precision=THRESHOLD)\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (y_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(y_test, y_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(y_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    return classification_report(y_test, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78bf3ea-3bda-4b5c-b0d0-98dd2b04c2cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "boost_results = []\n",
    "for df in datasets:\n",
    "    boost_results.append(get_boost_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545975ee-fe29-4c2b-8ba1-49e92f4113eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      0.98      0.99       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       0.99      0.99      0.99      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      0.99       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       0.99      1.00      1.00      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      0.98      0.99       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       0.99      0.99      0.99      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      0.98      0.98       400\n",
      "\n",
      "    accuracy                           0.99      2200\n",
      "   macro avg       0.99      0.99      0.99      2200\n",
      "weighted avg       0.99      0.99      0.99      2200\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1            0.9825             True   3 0.0017     0.9924  0.9825\n",
      "       2            0.9975             True   4 0.0022     0.9901  0.9975\n",
      "       3            0.9850             True   3 0.0017     0.9924  0.9850\n",
      "       4            0.9775             True   3 0.0017     0.9924  0.9775\n",
      "       5            1.0000             True   2 0.0011     0.9901  1.0000\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(boost_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a1907-c126-4431-898d-2b6222ebf410",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a6bf5a-9a63-487a-9217-3001a5cc634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f37d11f-c9ff-4e3f-b87a-baa802f9566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.tolist() if hasattr(labels, \"tolist\") else list(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        essay_id = self.encodings[\"essay_ids\"][idx]\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": torch.tensor(self.labels[essay_id], dtype=torch.long),\n",
    "            \"essay_id\": essay_id,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1467c4c2-fd43-48fb-a0bd-2fe888e91cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_sliding_window(texts, tokenizer, max_length=256, stride=128):\n",
    "    input_ids, attention_masks, essay_ids = [], [], []\n",
    "\n",
    "    for essay_id, text in enumerate(texts):\n",
    "        encoded = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            stride=stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        n_chunks = encoded[\"input_ids\"].shape[0]\n",
    "        input_ids.append(encoded[\"input_ids\"])\n",
    "        attention_masks.append(encoded[\"attention_mask\"])\n",
    "        essay_ids.extend([essay_id] * n_chunks)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.cat(input_ids),\n",
    "        \"attention_mask\": torch.cat(attention_masks),\n",
    "        \"essay_ids\": essay_ids,\n",
    "    }\n",
    "\n",
    "def get_bert_classification_report(\n",
    "    data,\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    max_length=256,\n",
    "    stride=128,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[\"text\"],\n",
    "        data[\"label\"],\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=data[\"label\"],\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_enc = tokenize_with_sliding_window(X_train, tokenizer, max_length, stride)\n",
    "    test_enc = tokenize_with_sliding_window(X_test, tokenizer, max_length, stride)\n",
    "\n",
    "    train_dataset = ChunkedTextDataset(train_enc, y_train)\n",
    "    test_dataset = ChunkedTextDataset(test_enc, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"essay_id\"}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            outputs.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    essay_probs = defaultdict(list)\n",
    "    essay_labels = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            essay_ids = batch[\"essay_id\"]\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"essay_id\"}\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            probs = F.softmax(outputs.logits, dim=1)[:, 1]\n",
    "\n",
    "            for i, essay_id in enumerate(essay_ids):\n",
    "                essay_probs[essay_id].append(probs[i].cpu())\n",
    "                essay_labels[essay_id] = labels[i].item()\n",
    "\n",
    "    final_scores, final_labels = [], []\n",
    "\n",
    "    for essay_id, probs_list in essay_probs.items():\n",
    "        mean_prob = torch.stack(probs_list).mean().item()\n",
    "        final_scores.append(mean_prob)\n",
    "        final_labels.append(essay_labels[essay_id])\n",
    "\n",
    "    final_scores = np.array(final_scores)\n",
    "    final_labels = np.array(final_labels)\n",
    "\n",
    "    rap = recall_at_precision(final_labels, final_scores, min_precision=THRESHOLD)\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (final_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(final_labels, final_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(final_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    return classification_report(final_labels, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4f3c26-ac4a-4c59-9420-0caf6c158919",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_results = []\n",
    "for df in datasets:\n",
    "    bert_results.append(get_bert_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5911ca7-0205-4b75-92c4-a3053abc4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      0.99       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       0.99      1.00      1.00      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       1.00      1.00      1.00      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       1.00      1.00      1.00      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       400\n",
      "\n",
      "    accuracy                           1.00      2200\n",
      "   macro avg       1.00      1.00      1.00      2200\n",
      "weighted avg       1.00      1.00      1.00      2200\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       200\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      1.00      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1            0.9975             True   4 0.0022     0.9901  0.9975\n",
      "       2            1.0000             True   4 0.0022     0.9901  1.0000\n",
      "       3            1.0000             True   4 0.0022     0.9901  1.0000\n",
      "       4            1.0000             True   4 0.0022     0.9901  1.0000\n",
      "       5            1.0000             True   2 0.0011     0.9901  1.0000\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(bert_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3aadf-2ba3-4b91-883c-052e58eb0490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (M2 GPU)",
   "language": "python",
   "name": "m2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
