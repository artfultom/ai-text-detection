{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdf1be83-f297-4de8-ad19-d88a6e2e47b5",
   "metadata": {},
   "source": [
    "# Анализ датасетов, сгенерированных моделью Mistral 7B, с помощью стандартных классификаторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97477742-ba32-469e-aae3-c897d2e9e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME_PREFIX = 'mistral_essays'\n",
    "DF_SPLIT = 9000\n",
    "DF_COUNT = 5\n",
    "THRESHOLD=0.99\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ecb18da-1111-4dac-a03e-cf0517b9ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, precision_recall_curve, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68bab0ae-85f5-4236-a9c7-1cce30ba6d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x136d36b70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaba4137-e4e6-4d65-ab1b-1c3b7114bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/human_essays.csv\", encoding=\"utf-8\").assign(label=0)[[\"text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bfc91a3-13e2-40da-b5fb-72a13eddfe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(orig_df: pd.DataFrame, filename: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Загружает датасет из CSV, добавляет метку и объединяет с исходным DataFrame. Затем перемешивает строки.\n",
    "\n",
    "    :param orig_df: исходный DataFrame\n",
    "    :param filename: путь к CSV-файлу\n",
    "    :return: объединённый и перемешанный DataFrame\n",
    "    \"\"\"\n",
    "    new_data = pd.read_csv(filename, encoding=\"utf-8\").assign(label=1)[[\"text\", \"label\"]]\n",
    "\n",
    "    result = pd.concat([orig_df, new_data], ignore_index=True).sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "515c723c-41a3-467f-bb27-e341c6b0ec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    get_dataset(df[0:DF_SPLIT], f\"../datasets/{FILE_NAME_PREFIX}_{i}.csv\")\n",
    "    for i in range(1, DF_COUNT + 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "017fc3e6-ee38-48b2-ba77-42e592dce0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(10500, 2), (10500, 2), (10500, 2), (10500, 2), (10500, 2)]\n"
     ]
    }
   ],
   "source": [
    "sizes = [dataset.shape for dataset in datasets]\n",
    "print(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38f9f073-8681-415d-8dbe-6b2e5ac86432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cash Flow Problems\\n\\nModern enterprises risk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. Overv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Social networking sites, news portals, and sea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. The R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The relationship between the Dominican Republi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Table of Contents\\n 1. Overview\\n 2. Funding\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In “Tropicalizations: Transcultural Representa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This paper investigates the current trends in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Introduction\\n\\nPolitical literature uses the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Commercial fishing is the process of taking fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Introduction\\n\\nThis inquiry focuses majorly o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Table of Contents\\n 1. Connections and How The...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Table of Contents\\n 1. Main research question\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>President Franklin D. Roosevelt, who served as...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. Ident...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Table of Contents\\n 1. Introduction\\n 2. Presc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Homeboy Industries is an organization dedicate...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Equine influenza, also known as equine flu, is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Due to rapid population increases, human-gener...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Transgender diversity has strongly integrated ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  label\n",
       "0   Cash Flow Problems\\n\\nModern enterprises risk ...      0\n",
       "1   Table of Contents\\n 1. Introduction\\n 2. Overv...      0\n",
       "2   Social networking sites, news portals, and sea...      0\n",
       "3   Table of Contents\\n 1. Introduction\\n 2. The R...      0\n",
       "4   The relationship between the Dominican Republi...      0\n",
       "5   Table of Contents\\n 1. Overview\\n 2. Funding\\n...      0\n",
       "6   In “Tropicalizations: Transcultural Representa...      0\n",
       "7   This paper investigates the current trends in ...      0\n",
       "8   Introduction\\n\\nPolitical literature uses the ...      0\n",
       "9   Commercial fishing is the process of taking fi...      0\n",
       "10  Introduction\\n\\nThis inquiry focuses majorly o...      0\n",
       "11  Table of Contents\\n 1. Connections and How The...      0\n",
       "12  Table of Contents\\n 1. Main research question\\...      0\n",
       "13  President Franklin D. Roosevelt, who served as...      1\n",
       "14  Table of Contents\\n 1. Introduction\\n 2. Ident...      0\n",
       "15  Table of Contents\\n 1. Introduction\\n 2. Presc...      0\n",
       "16  Homeboy Industries is an organization dedicate...      0\n",
       "17  Equine influenza, also known as equine flu, is...      1\n",
       "18  Due to rapid population increases, human-gener...      0\n",
       "19  Transgender diversity has strongly integrated ...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ea6a1c-e831-49c7-a085-648a0b88fc09",
   "metadata": {},
   "source": [
    "### Метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6716bdab-3f39-4c60-8ea4-639bea9fe1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_precision(y_true, y_scores, min_precision=0.995):\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        y_true, y_scores\n",
    "    )\n",
    "\n",
    "    valid = precision[:-1] >= min_precision\n",
    "\n",
    "    if not np.any(valid):\n",
    "        return {\n",
    "            \"recall\": 0.0,\n",
    "            \"precision\": float(precision.max()),\n",
    "            \"threshold\": None,\n",
    "            \"threshold_found\": False\n",
    "        }\n",
    "\n",
    "    idx = np.argmax(recall[:-1][valid])\n",
    "    valid_indices = np.where(valid)[0]\n",
    "    best_idx = valid_indices[idx]\n",
    "\n",
    "    return {\n",
    "        \"recall\": float(recall[best_idx]),\n",
    "        \"precision\": float(precision[best_idx]),\n",
    "        \"threshold\": float(thresholds[best_idx]),\n",
    "        \"threshold_found\": True\n",
    "    }\n",
    "\n",
    "def fp_metrics(y_true, y_scores, threshold):\n",
    "    y_pred = (y_scores >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    return {\n",
    "        \"fp\": int(fp),\n",
    "        \"fpr\": fp / (fp + tn + 1e-9),\n",
    "        \"precision\": tp / (tp + fp + 1e-9),\n",
    "        \"recall\": tp / (tp + fn + 1e-9),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb7fe3-d650-4fd4-bd91-da5c2ae20d78",
   "metadata": {},
   "source": [
    "### LogisticRegression + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1f9bc29-7204-4a95-a998-59fabc9da4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_classification_report(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[\"text\"],\n",
    "        data[\"label\"],\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=data[\"label\"],\n",
    "    )\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=5000,\n",
    "        ngram_range=(1, 2),\n",
    "    )\n",
    "\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, random_state=SEED)\n",
    "    model.fit(X_train_vec, y_train)\n",
    "\n",
    "    y_scores = model.predict_proba(X_test_vec)[:, 1]\n",
    "\n",
    "    rap = recall_at_precision(\n",
    "        y_test,\n",
    "        y_scores,\n",
    "        min_precision=THRESHOLD\n",
    "    )\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (y_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(y_test, y_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(y_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    return classification_report(y_test, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aa76a78-0a67-49f2-9991-f6229cad567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_results = []\n",
    "for df in datasets:\n",
    "    log_results.append(get_log_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee3ed0a3-36fe-46f2-9c4f-b09830fd97e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1800\n",
      "           1       0.99      0.96      0.97       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.98      0.99      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      1800\n",
      "           1       0.99      0.96      0.98       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.98      0.99      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1800\n",
      "           1       0.99      0.92      0.95       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.96      0.97      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1800\n",
      "           1       0.99      0.94      0.96       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.97      0.98      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1            0.9567             True   2 0.0011     0.9931  0.9567\n",
      "       2            0.9633             True   2 0.0011     0.9931  0.9633\n",
      "       3            0.9167             True   2 0.0011     0.9928  0.9167\n",
      "       4            0.9367             True   2 0.0011     0.9929  0.9367\n",
      "       5            1.0000             True   3 0.0017     0.9901  1.0000\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(log_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6dcaf1-758c-41b1-9b89-7de022655f3e",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1efefea0-0cb6-44c3-8325-ec5f0213ccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boost_classification_report(data):\n",
    "    df = data.copy()\n",
    "    df[\"tokens\"] = df[\"text\"].apply(lambda text: simple_preprocess(str(text)))\n",
    "\n",
    "    w2v_model = Word2Vec(\n",
    "        sentences=df[\"tokens\"],\n",
    "        vector_size=300,\n",
    "        window=7,\n",
    "        min_count=2,\n",
    "        workers=12,\n",
    "        sg=1,\n",
    "    )\n",
    "\n",
    "    def text_to_vector(tokens, model):\n",
    "        vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "        return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "    X = np.vstack([text_to_vector(tokens, w2v_model) for tokens in df[\"tokens\"]])\n",
    "    y = df[\"label\"].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=y,\n",
    "    )\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.5,\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=12,\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    rap = recall_at_precision(y_test, y_scores, min_precision=THRESHOLD)\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (y_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(y_test, y_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(y_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    return classification_report(y_test, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f78bf3ea-3bda-4b5c-b0d0-98dd2b04c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n",
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "boost_results = []\n",
    "for df in datasets:\n",
    "    boost_results.append(get_boost_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "545975ee-fe29-4c2b-8ba1-49e92f4113eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1800\n",
      "           1       0.99      0.92      0.95       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.96      0.97      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1800\n",
      "           1       0.99      0.91      0.95       300\n",
      "\n",
      "    accuracy                           0.99      2100\n",
      "   macro avg       0.99      0.95      0.97      2100\n",
      "weighted avg       0.99      0.99      0.99      2100\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1800\n",
      "           1       0.99      0.75      0.85       300\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.98      0.87      0.92      2100\n",
      "weighted avg       0.96      0.96      0.96      2100\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1800\n",
      "           1       0.99      0.80      0.88       300\n",
      "\n",
      "    accuracy                           0.97      2100\n",
      "   macro avg       0.98      0.90      0.93      2100\n",
      "weighted avg       0.97      0.97      0.97      2100\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      0.98      0.98       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       0.99      0.99      0.99      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1            0.9167             True   2 0.0011     0.9928  0.9167\n",
      "       2            0.9067             True   2 0.0011     0.9927  0.9067\n",
      "       3            0.7500             True   2 0.0011     0.9912  0.7500\n",
      "       4            0.7967             True   2 0.0011     0.9917  0.7967\n",
      "       5            0.9767             True   2 0.0011     0.9932  0.9767\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(boost_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101a1907-c126-4431-898d-2b6222ebf410",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a6bf5a-9a63-487a-9217-3001a5cc634c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f37d11f-c9ff-4e3f-b87a-baa802f9566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedTextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.tolist() if hasattr(labels, \"tolist\") else list(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        essay_id = self.encodings[\"essay_ids\"][idx]\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx],\n",
    "            \"labels\": torch.tensor(self.labels[essay_id], dtype=torch.long),\n",
    "            \"essay_id\": essay_id,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1467c4c2-fd43-48fb-a0bd-2fe888e91cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_with_sliding_window(texts, tokenizer, max_length=256, stride=128):\n",
    "    input_ids, attention_masks, essay_ids = [], [], []\n",
    "\n",
    "    for essay_id, text in enumerate(texts):\n",
    "        encoded = tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            stride=stride,\n",
    "            return_overflowing_tokens=True,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        n_chunks = encoded[\"input_ids\"].shape[0]\n",
    "        input_ids.append(encoded[\"input_ids\"])\n",
    "        attention_masks.append(encoded[\"attention_mask\"])\n",
    "        essay_ids.extend([essay_id] * n_chunks)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.cat(input_ids),\n",
    "        \"attention_mask\": torch.cat(attention_masks),\n",
    "        \"essay_ids\": essay_ids,\n",
    "    }\n",
    "\n",
    "def get_bert_classification_report(\n",
    "    data,\n",
    "    model_name=\"bert-base-uncased\",\n",
    "    max_length=256,\n",
    "    stride=128,\n",
    "    batch_size=32,\n",
    "    epochs=2,\n",
    "):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data[\"text\"],\n",
    "        data[\"label\"],\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=data[\"label\"],\n",
    "    )\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    train_enc = tokenize_with_sliding_window(X_train, tokenizer, max_length, stride)\n",
    "    test_enc = tokenize_with_sliding_window(X_test, tokenizer, max_length, stride)\n",
    "\n",
    "    train_dataset = ChunkedTextDataset(train_enc, y_train)\n",
    "    test_dataset = ChunkedTextDataset(test_enc, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"essay_id\"}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            outputs.loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    essay_probs = defaultdict(list)\n",
    "    essay_labels = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            essay_ids = batch[\"essay_id\"]\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            batch = {k: v.to(device) for k, v in batch.items() if k != \"essay_id\"}\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "            )\n",
    "\n",
    "            probs = F.softmax(outputs.logits, dim=1)[:, 1]\n",
    "\n",
    "            for i, essay_id in enumerate(essay_ids):\n",
    "                essay_probs[essay_id].append(probs[i].cpu())\n",
    "                essay_labels[essay_id] = labels[i].item()\n",
    "\n",
    "    final_scores, final_labels = [], []\n",
    "\n",
    "    for essay_id, probs_list in essay_probs.items():\n",
    "        mean_prob = torch.stack(probs_list).mean().item()\n",
    "        final_scores.append(mean_prob)\n",
    "        final_labels.append(essay_labels[essay_id])\n",
    "\n",
    "    final_scores = np.array(final_scores)\n",
    "    final_labels = np.array(final_labels)\n",
    "\n",
    "    rap = recall_at_precision(final_labels, final_scores, min_precision=THRESHOLD)\n",
    "\n",
    "    if rap[\"threshold_found\"]:\n",
    "        y_pred = (final_scores >= rap[\"threshold\"]).astype(int)\n",
    "        fp = fp_metrics(final_labels, final_scores, rap[\"threshold\"])\n",
    "    else:\n",
    "        y_pred = np.zeros_like(final_scores, dtype=int)\n",
    "        fp = None\n",
    "\n",
    "    return classification_report(final_labels, y_pred), rap, fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4f3c26-ac4a-4c59-9420-0caf6c158919",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "bert_results = []\n",
    "for df in datasets:\n",
    "    bert_results.append(get_bert_classification_report(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5911ca7-0205-4b75-92c4-a3053abc4d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Отчёт по датасету №1\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Отчёт по датасету №2\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Отчёт по датасету №3\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1800\n",
      "           1       0.99      0.74      0.85       300\n",
      "\n",
      "    accuracy                           0.96      2100\n",
      "   macro avg       0.97      0.87      0.91      2100\n",
      "weighted avg       0.96      0.96      0.96      2100\n",
      "\n",
      "Отчёт по датасету №4\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Отчёт по датасету №5\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1800\n",
      "           1       0.99      1.00      1.00       300\n",
      "\n",
      "    accuracy                           1.00      2100\n",
      "   macro avg       1.00      1.00      1.00      2100\n",
      "weighted avg       1.00      1.00      1.00      2100\n",
      "\n",
      "Сводная таблица\n",
      "\n",
      " dataset  recall@precision  threshold_found  fp    fpr  precision  recall\n",
      "       1              1.00             True   3 0.0017     0.9901    1.00\n",
      "       2              1.00             True   3 0.0017     0.9901    1.00\n",
      "       3              0.74             True   2 0.0011     0.9911    0.74\n",
      "       4              1.00             True   3 0.0017     0.9901    1.00\n",
      "       5              1.00             True   3 0.0017     0.9901    1.00\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for i, (report, rap, fp) in enumerate(bert_results, start=1):\n",
    "    print(f\"Отчёт по датасету №{i}\\n\")\n",
    "    print(report)\n",
    "\n",
    "    rows.append({\n",
    "        \"dataset\": i,\n",
    "        \"recall@precision\": rap[\"recall\"],\n",
    "        \"threshold_found\": rap[\"threshold_found\"],\n",
    "        \"fp\": fp[\"fp\"],\n",
    "        \"fpr\": fp[\"fpr\"],\n",
    "        \"precision\": fp[\"precision\"],\n",
    "        \"recall\": fp[\"recall\"],\n",
    "    })\n",
    "\n",
    "df_metrics = pd.DataFrame(rows)\n",
    "print(\"Сводная таблица\\n\")\n",
    "print(df_metrics.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb3aadf-2ba3-4b91-883c-052e58eb0490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (M2 GPU)",
   "language": "python",
   "name": "m2gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
